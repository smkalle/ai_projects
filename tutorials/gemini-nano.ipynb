{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "name": "Nano Banana (Gemini 2.5 Flash Image) – Real-World Use Cases",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf1f Nano Banana (Gemini 2.5 Flash Image) – Real-World Use Cases Notebook\n",
        "\n",
        "This hands-on notebook shows how to build **real applications** with **Gemini 2.5 Flash Image** (aka *Nano Banana*): text-to-image, editing, multi-image composition, batch pipelines, and lightweight evaluation.\n",
        "\n",
        "**Highlights**\n",
        "- Uses the **Google GenAI SDK** (`google-genai`) – the recommended client to access the Gemini API.\n",
        "- Model: `gemini-2.5-flash-image-preview` for image **generation & editing** (SynthID watermark is embedded in generated images by default).\n",
        "- Real-world scenarios: **E-commerce product backgrounds**, **Photo restoration for heritage**, **Marketing & social banners**, **Game asset previsualization**.\n",
        "- Includes **prompt engineering patterns** and a simple **SSIM** based quality check.\n",
        "\n",
        "> Notes:\n",
        "> - You need a **Gemini API key** from Google AI Studio. Set `GEMINI_API_KEY` as an environment variable before running.\n",
        "> - Respect content & safety policies. Only upload images you have rights to edit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup – Install & Auth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip -q install -U google-genai pillow numpy scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Set your API key: either set the env var before launching the kernel\n",
        "# or uncomment and paste below (not recommended to commit):\n",
        "# os.environ['GEMINI_API_KEY'] = 'YOUR_API_KEY_HERE'\n",
        "\n",
        "assert os.environ.get('GEMINI_API_KEY'), \"Please set GEMINI_API_KEY in your environment.\"\n",
        "client = genai.Client()\n",
        "MODEL = \"gemini-2.5-flash-image-preview\"\n",
        "print(\"Client ready; model:\", MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Text \u2192 Image – Prompt Patterns\n",
        "**Goal:** Generate consistent, high-quality images by describing scenes with camera/lighting style tokens when photorealism is desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "vscode": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "prompt_photo = (\n",
        "    \"A photorealistic product shot of a ceramic coffee mug on a wooden table, \"\n",
        "    \"morning window light, soft shadows, 50mm lens shallow depth of field, \"\n",
        "    \"crisp highlights on the rim, 3:2 aspect ratio\"\n",
        ")\n",
        "\n",
        "resp = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[prompt_photo]\n",
        ")\n",
        "\n",
        "# Save first returned image part (if any)\n",
        "img_bytes = None\n",
        "for part in resp.candidates[0].content.parts:\n",
        "    if getattr(part, 'inline_data', None):\n",
        "        img_bytes = part.inline_data.data\n",
        "        break\n",
        "\n",
        "if img_bytes:\n",
        "    img = Image.open(BytesIO(img_bytes))\n",
        "    img.save(\"t2i_product_shot.png\")\n",
        "    display(img)\n",
        "else:\n",
        "    print(\"No image bytes returned. Check quota/keys/prompt.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prompt Template Cheatsheet\n",
        "- **Photorealistic**: *shot type*, *subject*, *environment*, *lighting*, *mood*, *camera/lens*, *aspect ratio*\n",
        "- **Stylized/Illustration**: style (watercolor, cel-shaded, oil), palette, brushwork, texture, composition\n",
        "- **Logos/Text**: crisp vector style, kerning, alignment, background contrast, negative space\n",
        "\n",
        "Try editing the prompt and re-running to see how small changes affect results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Image + Text \u2192 Edited Image – Background Replacement\n",
        "**Goal:** Replace the background of an existing product photo for marketplace consistency.\n",
        "\n",
        "**Input:** `input_product.jpg` (provide your own file path)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "INPUT_PATH = \"input_product.jpg\"  # TODO: replace with your image path\n",
        "assert os.path.exists(INPUT_PATH), f\"Provide an input image at {INPUT_PATH}\"\n",
        "\n",
        "image = Image.open(INPUT_PATH).convert(\"RGB\")\n",
        "\n",
        "edit_prompt = (\n",
        "    \"Replace the background with a clean, matte light-gray studio backdrop, \"\n",
        "    \"keep the product edges crisp, no reflections, maintain natural shadows\"\n",
        ")\n",
        "\n",
        "resp_edit = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[edit_prompt, image]\n",
        ")\n",
        "\n",
        "edited_bytes = None\n",
        "for part in resp_edit.candidates[0].content.parts:\n",
        "    if getattr(part, 'inline_data', None):\n",
        "        edited_bytes = part.inline_data.data\n",
        "        break\n",
        "\n",
        "if edited_bytes:\n",
        "    edited_img = Image.open(BytesIO(edited_bytes))\n",
        "    edited_img.save(\"edited_product_gray_bg.png\")\n",
        "    display(edited_img)\n",
        "else:\n",
        "    print(\"No edited image returned. Verify API/model availability.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Multi-Image Composition – Style Transfer / Layout Merge\n",
        "**Goal:** Compose a lifestyle scene using a product photo + a brand style guide image.\n",
        "\n",
        "**Inputs:** `product.png` and `style_ref.png`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "PRODUCT = \"product.png\"   # product cutout or clean photo\n",
        "STYLE   = \"style_ref.png\" # e.g., brand palette/moodboard\n",
        "assert os.path.exists(PRODUCT) and os.path.exists(STYLE), \"Add PRODUCT and STYLE images.\"\n",
        "\n",
        "img_product = Image.open(PRODUCT).convert(\"RGB\")\n",
        "img_style = Image.open(STYLE).convert(\"RGB\")\n",
        "\n",
        "compose_prompt = (\n",
        "    \"Compose a lifestyle photo on a wooden kitchen counter, soft window light. \"\n",
        "    \"Use the color palette from the style reference, keep product scale natural, \"\n",
        "    \"subtle depth of field, premium brand feel.\"\n",
        ")\n",
        "\n",
        "resp_comp = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[compose_prompt, img_product, img_style]\n",
        ")\n",
        "\n",
        "comp_bytes = None\n",
        "for part in resp_comp.candidates[0].content.parts:\n",
        "    if getattr(part, 'inline_data', None):\n",
        "        comp_bytes = part.inline_data.data\n",
        "        break\n",
        "\n",
        "if comp_bytes:\n",
        "    comp_img = Image.open(BytesIO(comp_bytes))\n",
        "    comp_img.save(\"composed_lifestyle.png\")\n",
        "    display(comp_img)\n",
        "else:\n",
        "    print(\"No composition image returned.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Iterative Refinement – Conversational Edits\n",
        "You can chain edits by passing the **previous output image** back with a new prompt. This mimics a designer feedback loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load the composed image and tweak tones/props\n",
        "BASE_EDIT = \"composed_lifestyle.png\"\n",
        "assert os.path.exists(BASE_EDIT), \"Run the previous cell to create composed_lifestyle.png\"\n",
        "\n",
        "base_img = Image.open(BASE_EDIT).convert(\"RGB\")\n",
        "refine_prompt = (\n",
        "    \"Warm up the color temperature slightly, add soft morning sun beams, \"\n",
        "    \"increase the contrast subtly, remove any harsh reflections.\"\n",
        ")\n",
        "\n",
        "resp_refine = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[refine_prompt, base_img]\n",
        ")\n",
        "\n",
        "refined_bytes = None\n",
        "for part in resp_refine.candidates[0].content.parts:\n",
        "    if getattr(part, 'inline_data', None):\n",
        "        refined_bytes = part.inline_data.data\n",
        "        break\n",
        "\n",
        "if refined_bytes:\n",
        "    refined_img = Image.open(BytesIO(refined_bytes))\n",
        "    refined_img.save(\"composed_lifestyle_refined.png\")\n",
        "    display(refined_img)\n",
        "else:\n",
        "    print(\"No refined image returned.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Quick Evaluation – SSIM (Structural Similarity)\n",
        "For editing workflows, compare before/after to ensure you **preserved product details** (edges, logos). SSIM \u2208 [0,1] (higher is closer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def to_gray(img: Image.Image):\n",
        "    return np.array(img.convert(\"L\")) / 255.0\n",
        "\n",
        "orig = Image.open(INPUT_PATH).convert(\"RGB\")\n",
        "edited = Image.open(\"edited_product_gray_bg.png\").convert(\"RGB\")\n",
        "\n",
        "ssim_score, _ = ssim(to_gray(orig), to_gray(edited), full=True)\n",
        "print(f\"SSIM (original vs edited): {ssim_score:.3f}\")\n",
        "display(orig, edited)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcca Real-World Use Case Pipelines\n",
        "Below are **four** production-style mini-pipelines you can adapt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case A) E-commerce – Unified Backgrounds for Catalog\n",
        "**Goal:** Standardize product backgrounds (light gray/white) and generate a **lifestyle alt** for PDP/ads.\n",
        "\n",
        "**Inputs:** folder of product photos (`ecom_in/`). Outputs go to `ecom_out/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import glob, pathlib\n",
        "\n",
        "in_dir = pathlib.Path(\"ecom_in\")\n",
        "out_dir = pathlib.Path(\"ecom_out\")\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "bg_prompt = (\n",
        "    \"Replace the background with a clean white sweep, keep natural product shadow, \"\n",
        "    \"no clipping, preserve edges, center the product, PDP-ready.\"\n",
        ")\n",
        "\n",
        "lifestyle_prompt = (\n",
        "    \"Create a subtle lifestyle setting: matte wooden shelf, soft daylight, \"\n",
        "    \"use muted, premium color palette, keep product scale realistic.\"\n",
        ")\n",
        "\n",
        "for path in glob.glob(str(in_dir / \"*.jpg\")) + glob.glob(str(in_dir / \"*.png\")):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    # Background standardization\n",
        "    resp_bg = client.models.generate_content(model=MODEL, contents=[bg_prompt, img])\n",
        "    bg_bytes = None\n",
        "    for p in resp_bg.candidates[0].content.parts:\n",
        "        if getattr(p, 'inline_data', None):\n",
        "            bg_bytes = p.inline_data.data\n",
        "            break\n",
        "    if bg_bytes:\n",
        "        out_bg = Image.open(BytesIO(bg_bytes))\n",
        "        out_bg.save(out_dir / (pathlib.Path(path).stem + \"_bg.png\"))\n",
        "\n",
        "    # Lifestyle alt\n",
        "    resp_ls = client.models.generate_content(model=MODEL, contents=[lifestyle_prompt, img])\n",
        "    ls_bytes = None\n",
        "    for p in resp_ls.candidates[0].content.parts:\n",
        "        if getattr(p, 'inline_data', None):\n",
        "            ls_bytes = p.inline_data.data\n",
        "            break\n",
        "    if ls_bytes:\n",
        "        out_ls = Image.open(BytesIO(ls_bytes))\n",
        "        out_ls.save(out_dir / (pathlib.Path(path).stem + \"_lifestyle.png\"))\n",
        "\n",
        "print(\"E-commerce batch complete -> ecom_out/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case B) Photo Restoration – Heritage/Archives\n",
        "**Goal:** Denoise, remove scratches, and gently color-correct aged scans while **preserving identity**.\n",
        "\n",
        "**Input:** `heritage_in/damaged_*.png`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "in_dir = pathlib.Path(\"heritage_in\")\n",
        "out_dir = pathlib.Path(\"heritage_out\")\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "restore_prompt = (\n",
        "    \"Restore the photograph: remove scratches, reduce film grain, recover details, \"\n",
        "    \"gentle color correction, preserve facial identity, no AI beautification.\"\n",
        ")\n",
        "\n",
        "for path in glob.glob(str(in_dir / \"damaged_*.png\")):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    resp_r = client.models.generate_content(model=MODEL, contents=[restore_prompt, img])\n",
        "    r_bytes = None\n",
        "    for p in resp_r.candidates[0].content.parts:\n",
        "        if getattr(p, 'inline_data', None):\n",
        "            r_bytes = p.inline_data.data\n",
        "            break\n",
        "    if r_bytes:\n",
        "        out = Image.open(BytesIO(r_bytes))\n",
        "        out.save(out_dir / (pathlib.Path(path).stem + \"_restored.png\"))\n",
        "\n",
        "print(\"Heritage restoration batch complete -> heritage_out/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case C) Marketing – Banner & Social Variants (with Text)\n",
        "**Goal:** Generate banner backgrounds and produce **multiple crops/aspect ratios** for social platforms.\n",
        "\n",
        "We’ll generate a base key visual, then ask for **layout-aware** variations (e.g., safe space for headline/top-left logo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "kv_prompt = (\n",
        "    \"Design a clean tech banner background with gradient blues and purples, \"\n",
        "    \"soft bokeh lights, diagonal energy lines, ample negative space top-left \"\n",
        "    \"for a headline and logo.\"\n",
        ")\n",
        "resp_kv = client.models.generate_content(model=MODEL, contents=[kv_prompt])\n",
        "kv_bytes = None\n",
        "for p in resp_kv.candidates[0].content.parts:\n",
        "    if getattr(p, 'inline_data', None):\n",
        "        kv_bytes = p.inline_data.data\n",
        "        break\n",
        "if kv_bytes:\n",
        "    kv_img = Image.open(BytesIO(kv_bytes)).convert(\"RGB\")\n",
        "    kv_img.save(\"marketing_kv_base.png\")\n",
        "    display(kv_img)\n",
        "\n",
        "    # Create social crops: 1:1, 16:9, 9:16 via simple padding/cropping (placeholder logic)\n",
        "    def resize_aspect(img, target_w, target_h):\n",
        "        return img.resize((target_w, target_h), Image.LANCZOS)\n",
        "\n",
        "    resize_aspect(kv_img, 1200, 1200).save(\"marketing_kv_square_1200.png\")\n",
        "    resize_aspect(kv_img, 1600, 900).save(\"marketing_kv_16x9_1600x900.png\")\n",
        "    resize_aspect(kv_img, 1080, 1920).save(\"marketing_kv_9x16_1080x1920.png\")\n",
        "else:\n",
        "    print(\"KV generation failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case D) Game/Sim – Fast Asset Previz\n",
        "**Goal:** Generate concept-art variants for props with **consistency** across a theme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "theme = \"retro-futuristic space diner\"\n",
        "prop = \"coffee machine\"\n",
        "\n",
        "variants = [\n",
        "    f\"Concept art, {prop}, {theme}, chrome accents, neon highlights, ambient occlusion, orthographic view\",\n",
        "    f\"Concept art, {prop}, {theme}, pastel palette, soft reflections, exploded view schematic\",\n",
        "    f\"Concept art, {prop}, {theme}, dark mode, rim lighting, top-down view\"\n",
        "]\n",
        "\n",
        "for i, ptxt in enumerate(variants, 1):\n",
        "    r = client.models.generate_content(model=MODEL, contents=[ptxt])\n",
        "    b = None\n",
        "    for prt in r.candidates[0].content.parts:\n",
        "        if getattr(prt, 'inline_data', None):\n",
        "            b = prt.inline_data.data\n",
        "            break\n",
        "    if b:\n",
        "        Image.open(BytesIO(b)).save(f\"asset_previz_{i}.png\")\n",
        "print(\"Game asset concept variants saved: asset_previz_*.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcdd Prompt Engineering Patterns\n",
        "1. **Describe the scene** in a sentence or two; avoid isolated keywords.\n",
        "2. For photorealism, add **camera/lens** and **lighting**.\n",
        "3. For edits, be explicit about **what to preserve** (edges/logos/faces) and **what to change**.\n",
        "4. Iterate: apply small, **targeted refinements** using the previous output.\n",
        "5. Establish **brand consistency**: maintain palettes, composition rules, and negative space conventions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udee0\ufe0f Batch API Notes & Production Tips\n",
        "- Prefer **batching** and **idempotent filenames** in pipelines.\n",
        "- Keep a **manifest (CSV/JSON)** with input \u2192 output mappings for traceability.\n",
        "- Add **lightweight QA** (e.g., SSIM against originals in edit flows; human spot-checking for brand compliance).\n",
        "- Respect licensing and privacy. All generated images include **SynthID** watermarking for provenance.\n"
      ]
    }
  ]
}
```0
