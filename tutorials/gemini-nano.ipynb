{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Nano Banana (Gemini 2.5 Flash Image) – Real-World Use Cases Notebook\n",
        "\n",
        "This hands-on notebook shows how to build real applications with Gemini 2.5 Flash Image (aka Nano Banana): text-to-image, image editing, multi-image composition, batch pipelines, and lightweight evaluation.\n",
        "\n",
        "Highlights:\n",
        "- Uses the Google GenAI SDK (python package: google-genai).\n",
        "- Model: \"gemini-2.5-flash-image-preview\" for generation and editing. Outputs include SynthID watermarking by default.\n",
        "- Scenarios: e-commerce background standardization, heritage photo restoration, marketing banners, game asset previsualization.\n",
        "\n",
        "Note: You need a Gemini API key from Google AI Studio. Set GEMINI_API_KEY as an environment variable before running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup – Install and Authenticate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip -q install -U google-genai pillow numpy scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure API key is present in environment.\n",
        "assert os.environ.get(\"GEMINI_API_KEY\"), \"Please set GEMINI_API_KEY in your environment.\"\n",
        "\n",
        "client = genai.Client()\n",
        "MODEL = \"gemini-2.5-flash-image-preview\"\n",
        "print(\"Client initialized. Using model:\", MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Text to Image – Prompt Patterns\n",
        "Goal: Generate consistent, high-quality images using camera and lighting descriptors when photorealism is desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "prompt_photo = (\n",
        "    \"A photorealistic product shot of a ceramic coffee mug on a wooden table, \"\n",
        "    \"morning window light, soft shadows, 50mm lens shallow depth of field, \"\n",
        "    \"crisp highlights on the rim, 3:2 aspect ratio\"\n",
        ")\n",
        "\n",
        "resp = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[prompt_photo]\n",
        ")\n",
        "\n",
        "img_bytes = None\n",
        "if resp and resp.candidates:\n",
        "    for part in resp.candidates[0].content.parts:\n",
        "        if getattr(part, \"inline_data\", None):\n",
        "            img_bytes = part.inline_data.data\n",
        "            break\n",
        "\n",
        "if img_bytes:\n",
        "    img = Image.open(BytesIO(img_bytes))\n",
        "    img.save(\"t2i_product_shot.png\")\n",
        "    display(img)\n",
        "else:\n",
        "    print(\"No image bytes returned. Check quota, keys, or prompt.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prompt template cheatsheet:\n",
        "- Photorealistic: shot type, subject, environment, lighting, mood, camera/lens, aspect ratio.\n",
        "- Stylized/Illustration: style (watercolor, cel-shaded, oil), palette, brushwork, texture, composition.\n",
        "- Logos/Text: vector style, kerning, alignment, background contrast, negative space.\n",
        "Experiment: Tweak one descriptor at a time to observe the effect on outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Image plus Text to Edited Image – Background Replacement\n",
        "Goal: Replace background of an existing product image for consistent catalog presentation.\n",
        "Input: set INPUT_PATH to an existing image file (jpg or png)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "INPUT_PATH = \"input_product.jpg\"  # Replace with your file path\n",
        "assert Path(INPUT_PATH).exists(), f\"Provide an input image at {INPUT_PATH}\"\n",
        "\n",
        "image = Image.open(INPUT_PATH).convert(\"RGB\")\n",
        "\n",
        "edit_prompt = (\n",
        "    \"Replace the background with a clean, matte light-gray studio backdrop, \"\n",
        "    \"keep the product edges crisp, no reflections, maintain natural soft shadow\"\n",
        ")\n",
        "\n",
        "resp_edit = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[edit_prompt, image]\n",
        ")\n",
        "\n",
        "edited_bytes = None\n",
        "if resp_edit and resp_edit.candidates:\n",
        "    for part in resp_edit.candidates[0].content.parts:\n",
        "        if getattr(part, \"inline_data\", None):\n",
        "            edited_bytes = part.inline_data.data\n",
        "            break\n",
        "\n",
        "if edited_bytes:\n",
        "    edited_img = Image.open(BytesIO(edited_bytes))\n",
        "    edited_img.save(\"edited_product_gray_bg.png\")\n",
        "    display(edited_img)\n",
        "else:\n",
        "    print(\"No edited image returned.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Multi-Image Composition – Style Reference and Layout Merge\n",
        "Goal: Compose a lifestyle scene using a product photo and a brand style reference.\n",
        "Inputs: product.png and style_ref.png (both must exist)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "PRODUCT = \"product.png\"\n",
        "STYLE = \"style_ref.png\"\n",
        "assert Path(PRODUCT).exists() and Path(STYLE).exists(), \"Add PRODUCT and STYLE images.\"\n",
        "\n",
        "img_product = Image.open(PRODUCT).convert(\"RGB\")\n",
        "img_style = Image.open(STYLE).convert(\"RGB\")\n",
        "\n",
        "compose_prompt = (\n",
        "    \"Compose a lifestyle photo on a wooden kitchen counter, soft window light. \"\n",
        "    \"Use the color palette from the style reference, keep product scale natural, \"\n",
        "    \"subtle depth of field, premium brand feel.\"\n",
        ")\n",
        "\n",
        "resp_comp = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[compose_prompt, img_product, img_style]\n",
        ")\n",
        "\n",
        "comp_bytes = None\n",
        "if resp_comp and resp_comp.candidates:\n",
        "    for part in resp_comp.candidates[0].content.parts:\n",
        "        if getattr(part, \"inline_data\", None):\n",
        "            comp_bytes = part.inline_data.data\n",
        "            break\n",
        "\n",
        "if comp_bytes:\n",
        "    comp_img = Image.open(BytesIO(comp_bytes))\n",
        "    comp_img.save(\"composed_lifestyle.png\")\n",
        "    display(comp_img)\n",
        "else:\n",
        "    print(\"No composition image returned.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Iterative Refinement – Conversational Edits\n",
        "You can chain edits by passing the previous output with a new prompt to simulate a designer feedback loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "BASE_EDIT = \"composed_lifestyle.png\"\n",
        "assert Path(BASE_EDIT).exists(), \"Run the previous cell to create composed_lifestyle.png\"\n",
        "\n",
        "base_img = Image.open(BASE_EDIT).convert(\"RGB\")\n",
        "refine_prompt = (\n",
        "    \"Warm up the color temperature slightly, add soft morning sun beams, \"\n",
        "    \"increase contrast subtly, remove any harsh reflections\"\n",
        ")\n",
        "\n",
        "resp_refine = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[refine_prompt, base_img]\n",
        ")\n",
        "\n",
        "refined_bytes = None\n",
        "if resp_refine and resp_refine.candidates:\n",
        "    for part in resp_refine.candidates[0].content.parts:\n",
        "        if getattr(part, \"inline_data\", None):\n",
        "            refined_bytes = part.inline_data.data\n",
        "            break\n",
        "\n",
        "if refined_bytes:\n",
        "    refined_img = Image.open(BytesIO(refined_bytes))\n",
        "    refined_img.save(\"composed_lifestyle_refined.png\")\n",
        "    display(refined_img)\n",
        "else:\n",
        "    print(\"No refined image returned.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Quick Evaluation – SSIM (Structural Similarity)\n",
        "For editing workflows, compare before and after to ensure key details are preserved. SSIM in [0,1], higher is closer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def to_gray(img):\n",
        "    return np.array(img.convert(\"L\"), dtype=np.float32) / 255.0\n",
        "\n",
        "orig = Image.open(INPUT_PATH).convert(\"RGB\")\n",
        "edited = Image.open(\"edited_product_gray_bg.png\").convert(\"RGB\")\n",
        "\n",
        "score, _ = ssim(to_gray(orig), to_gray(edited), full=True)\n",
        "print(f\"SSIM (original vs edited): {score:.3f}\")\n",
        "display(orig, edited)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real-World Use Case Pipelines",
        "Below are four production-style mini-pipelines you can adapt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case A) E-commerce – Unified Backgrounds for Catalog\n",
        "Goal: Standardize product backgrounds (light gray or white) and generate a lifestyle alternative for PDP or ads.\n",
        "Inputs: folder of product photos in ecom_in/. Outputs go to ecom_out/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "in_dir = Path(\"ecom_in\")\n",
        "out_dir = Path(\"ecom_out\")\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "bg_prompt = (\n",
        "    \"Replace the background with a clean white sweep, keep natural product shadow, \"\n",
        "    \"no clipping, preserve edges, center the product, PDP-ready\"\n",
        ")\n",
        "\n",
        "lifestyle_prompt = (\n",
        "    \"Create a subtle lifestyle setting: matte wooden shelf, soft daylight, muted premium palette, realistic scale\"\n",
        ")\n",
        "\n",
        "paths = glob.glob(str(in_dir / \"*.jpg\")) + glob.glob(str(in_dir / \"*.png\"))\n",
        "for path in paths:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    resp_bg = client.models.generate_content(model=MODEL, contents=[bg_prompt, img])\n",
        "    bg_bytes = None\n",
        "    if resp_bg and resp_bg.candidates:\n",
        "        for p in resp_bg.candidates[0].content.parts:\n",
        "            if getattr(p, \"inline_data\", None):\n",
        "                bg_bytes = p.inline_data.data\n",
        "                break\n",
        "    if bg_bytes:\n",
        "        out_bg = Image.open(BytesIO(bg_bytes))\n",
        "        out_bg.save(out_dir / (Path(path).stem + \"_bg.png\"))\n",
        "\n",
        "    resp_ls = client.models.generate_content(model=MODEL, contents=[lifestyle_prompt, img])\n",
        "    ls_bytes = None\n",
        "    if resp_ls and resp_ls.candidates:\n",
        "        for p in resp_ls.candidates[0].content.parts:\n",
        "            if getattr(p, \"inline_data\", None):\n",
        "                ls_bytes = p.inline_data.data\n",
        "                break\n",
        "    if ls_bytes:\n",
        "        out_ls = Image.open(BytesIO(ls_bytes))\n",
        "        out_ls.save(out_dir / (Path(path).stem + \"_lifestyle.png\"))\n",
        "\n",
        "print(\"E-commerce batch complete -> ecom_out/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case B) Photo Restoration – Heritage and Archives\n",
        "Goal: Denoise, remove scratches, gentle color correction, preserve identity.\n",
        "Input: heritage_in/damaged_*.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "in_dir = Path(\"heritage_in\")\n",
        "out_dir = Path(\"heritage_out\")\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "restore_prompt = (\n",
        "    \"Restore the photograph: remove scratches, reduce film grain, recover details, \"\n",
        "    \"gentle color correction, preserve facial identity, no beautification\"\n",
        ")\n",
        "\n",
        "paths = glob.glob(str(in_dir / \"damaged_*.png\"))\n",
        "for path in paths:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    resp_r = client.models.generate_content(model=MODEL, contents=[restore_prompt, img])\n",
        "    r_bytes = None\n",
        "    if resp_r and resp_r.candidates:\n",
        "        for p in resp_r.candidates[0].content.parts:\n",
        "            if getattr(p, \"inline_data\", None):\n",
        "                r_bytes = p.inline_data.data\n",
        "                break\n",
        "    if r_bytes:\n",
        "        out = Image.open(BytesIO(r_bytes))\n",
        "        out.save(out_dir / (Path(path).stem + \"_restored.png\"))\n",
        "\n",
        "print(\"Heritage restoration batch complete -> heritage_out/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case C) Marketing – Banner and Social Variants\n",
        "Goal: Generate banner backgrounds and produce multiple crops/aspect ratios for social platforms.\n",
        "We generate a base key visual, then create 1:1, 16:9, and 9:16 variants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "kv_prompt = (\n",
        "    \"Design a clean tech banner background with gradient blues and purples, \"\n",
        "    \"soft bokeh lights, diagonal energy lines, ample negative space top-left for a headline and logo\"\n",
        ")\n",
        "resp_kv = client.models.generate_content(model=MODEL, contents=[kv_prompt])\n",
        "kv_bytes = None\n",
        "if resp_kv and resp_kv.candidates:\n",
        "    for p in resp_kv.candidates[0].content.parts:\n",
        "        if getattr(p, \"inline_data\", None):\n",
        "            kv_bytes = p.inline_data.data\n",
        "            break\n",
        "if kv_bytes:\n",
        "    kv_img = Image.open(BytesIO(kv_bytes)).convert(\"RGB\")\n",
        "    kv_img.save(\"marketing_kv_base.png\")\n",
        "    display(kv_img)\n",
        "\n",
        "    def resize_exact(img, w, h):\n",
        "        return img.resize((w, h), Image.LANCZOS)\n",
        "\n",
        "    resize_exact(kv_img, 1200, 1200).save(\"marketing_kv_square_1200.png\")\n",
        "    resize_exact(kv_img, 1600, 900).save(\"marketing_kv_16x9_1600x900.png\")\n",
        "    resize_exact(kv_img, 1080, 1920).save(\"marketing_kv_9x16_1080x1920.png\")\n",
        "else:\n",
        "    print(\"KV generation failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case D) Game and Simulation – Fast Asset Previsualization\n",
        "Goal: Generate concept-art variants for props with consistent theme and viewpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "theme = \"retro-futuristic space diner\"\n",
        "prop = \"coffee machine\"\n",
        "\n",
        "variants = [\n",
        "    f\"Concept art, {prop}, {theme}, chrome accents, neon highlights, ambient occlusion, orthographic view\",\n",
        "    f\"Concept art, {prop}, {theme}, pastel palette, soft reflections, exploded view schematic\",\n",
        "    f\"Concept art, {prop}, {theme}, dark mode, rim lighting, top-down view\"\n",
        "]\n",
        "\n",
        "for i, ptxt in enumerate(variants, 1):\n",
        "    r = client.models.generate_content(model=MODEL, contents=[ptxt])\n",
        "    b = None\n",
        "    if r and r.candidates:\n",
        "        for prt in r.candidates[0].content.parts:\n",
        "            if getattr(prt, \"inline_data\", None):\n",
        "                b = prt.inline_data.data\n",
        "                break\n",
        "    if b:\n",
        "        Image.open(BytesIO(b)).save(f\"asset_previz_{i}.png\")\n",
        "print(\"Game asset concept variants saved: asset_previz_*.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Engineering Patterns\n",
        "1. Describe the scene in a sentence or two; avoid isolated keywords.\n",
        "2. For photorealism, add camera or lens details and lighting.\n",
        "3. For edits, be explicit about what to preserve (edges, logos, faces) and what to change.\n",
        "4. Iterate with small, targeted refinements using the previous output.\n",
        "5. Maintain brand consistency via palettes, composition rules, and negative space conventions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch API Notes and Production Tips\n",
        "- Prefer batching and idempotent filenames in pipelines.\n",
        "- Keep a manifest (CSV or JSON) with input to output mappings for traceability.\n",
        "- Add lightweight QA (for example, SSIM for edit flows; human spot checks for brand compliance).\n",
        "- Respect licensing and privacy. Generated images include SynthID watermarking for provenance."
      ]
    }
  ]
}
