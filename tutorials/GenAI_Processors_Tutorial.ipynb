{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4bde6e",
   "metadata": {},
   "source": [
    "# Building Asynchronous Gemini Pipelines with **GenAI Processors**\n",
    "\n",
    "**Release date:** 10Â JulÂ 2025  \n",
    "**Library version used:** `genai-processorsÂ 1.0.3`  \n",
    "\n",
    "> *This tutorial notebook is designed for absolute beginners. Each section mixes explanation with runnable code so you can learn by doing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadb400",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "2. [Installation](#Installation)\n",
    "3. [Quickstart](#Quickstart)\n",
    "4. [Core Concepts](#Core-Concepts)\n",
    "5. [Handsâ€‘On Examples](#Hands-On-Examples)\n",
    "6. [Testing Your Processors](#Testing-Your-Processors)\n",
    "7. [Performance Tips](#Performance-Tips)\n",
    "8. [Deployment Snippet](#Deployment-Snippet)\n",
    "9. [Next Steps & Exercises](#Next-Steps-&-Exercises)\n",
    "10. [Resources](#Resources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08577886",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "- **PythonÂ â‰¥Â 3.10**\n",
    "- A **Google Cloud** project with the **Gemini API** enabled (for live examples)\n",
    "- Basic familiarity with running cells in Jupyter\n",
    "- A virtual environment is strongly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8822b04",
   "metadata": {},
   "source": [
    "## 2. Installation\n",
    "Run the cell below to install the library. The `--upgrade` flag is a good habit to make sure you get the latest patch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip wheel\n",
    "!pip install genai-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0007e5",
   "metadata": {},
   "source": [
    "## 3. Quickstart<a id='Quickstart'></a>\n",
    "The next cell creates the simplest possible pipeline: text in â†’ Gemini model â†’ text out. The call is **fully async**, so we wrap it in an `asyncio` event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f78c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from genai_processors.core import genai_model\n",
    "from genai_processors import content_api\n",
    "\n",
    "async def hello_gemini():\n",
    "    pipeline = genai_model.GenaiModel(model_name='gemini-2.0-flash')\n",
    "    inp = content_api.from_text('Hello, GenAI Processors!')\n",
    "    async for part in pipeline(inp):\n",
    "        if part.text:\n",
    "            print(part.text)\n",
    "\n",
    "await hello_gemini()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1c65",
   "metadata": {},
   "source": [
    "## 4. Core Concepts<a id='Core-Concepts'></a>\n",
    "\n",
    "### 4.1 Processor & PartProcessor\n",
    "`Processor` is an **async function or class** that receives a *stream* of `ProcessorPart` objects and emits a (possibly transformed) stream.  \n",
    "Use the `@processor.PartProcessor` decorator for quick oneâ€‘off functions.\n",
    "\n",
    "### 4.2 ProcessorPart\n",
    "A `ProcessorPart` wraps **content + metadata** (e.g.\\ MIME type, role, custom attributes).  \n",
    "It can represent text, images, audio frames, or arbitrary JSON.\n",
    "\n",
    "### 4.3 Chaining & Parallelism\n",
    "- Use **`+`** to chain processors sequentially (output of left â†’ input of right).  \n",
    "- Use **`//`** to run processors in *parallel* on the same input stream.\n",
    "\n",
    "The library schedules downstream work as soon as a **single part** is ready, which drastically cuts **Timeâ€‘Toâ€‘Firstâ€‘Token** compared with fully synchronous pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d054b",
   "metadata": {},
   "source": [
    "## 5. Handsâ€‘On Examples<a id='Hands-On-Examples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc0031",
   "metadata": {},
   "source": [
    "### 5.1 ExampleÂ 1 â€“ Uppercase â†’ Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai_processors import processor\n",
    "from genai_processors.core import genai_model, streams, content_api\n",
    "\n",
    "@processor.PartProcessor\n",
    "async def uppercase(part):\n",
    "    if part.text:\n",
    "        part.text = part.text.upper()\n",
    "    return part\n",
    "\n",
    "async def run_pipeline():\n",
    "    text_pipeline = uppercase + genai_model.GenaiModel(model_name='gemini-2.0-pro')\n",
    "    inp = content_api.from_text('Synchronous code is so 2024.')\n",
    "    async for part in text_pipeline(inp):\n",
    "        if part.text:\n",
    "            print(part.text)\n",
    "\n",
    "await run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd233041",
   "metadata": {},
   "source": [
    "### 5.2 ExampleÂ 2 â€“ Live Audio & Video Agent *(optional)*\n",
    "This example needs microphone/camera access and valid Gemini Live API credentials, so feel free to skip in a binder environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and configure credentials first\n",
    "# from genai_processors.core import audio_io, video, live_model, streams\n",
    "# cam_mic   = video.VideoIn() + audio_io.PyAudioIn()\n",
    "# speaker   = audio_io.PyAudioOut()\n",
    "# live_llm  = live_model.LiveProcessor(model_name='gemini-2.0-pro')\n",
    "# live_agent = cam_mic + live_llm + speaker\n",
    "# await live_agent(streams.endless_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd267cf6",
   "metadata": {},
   "source": [
    "### 5.3 ExampleÂ 3 â€“ Emitting Custom JSON Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai_processors import processor, content_api, streams\n",
    "\n",
    "@processor.PartProcessor\n",
    "async def sentiment_json(part):\n",
    "    if part.text:\n",
    "        score = 1 if 'ðŸ™‚' in part.text else -1\n",
    "        yield content_api.from_json({'sentiment': score})\n",
    "\n",
    "async def demo_json():\n",
    "    pipe = sentiment_json\n",
    "    inp = content_api.from_text('I love async programming ðŸ™‚')\n",
    "    async for part in pipe(inp):\n",
    "        print(part.json())\n",
    "\n",
    "await demo_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a51c4",
   "metadata": {},
   "source": [
    "## 6. Testing Your Processors<a id='Testing-Your-Processors'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running `pytest`, save this as test_uppercase.py\n",
    "import pytest, asyncio\n",
    "from genai_processors import content_api, streams\n",
    "from tutorial_notebook import uppercase\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_uppercase():\n",
    "    s = streams.stream_content(['abc'])\n",
    "    out = [p async for p in uppercase(s)]\n",
    "    assert out[0].text == 'ABC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f8313",
   "metadata": {},
   "source": [
    "## 7. Performance Tips<a id='Performance-Tips'></a>\n",
    "- **Chunk large inputs:** emit smaller `ProcessorPart`s so downstream stages start sooner.\n",
    "- **Avoid global state:** processors should be pure; easier to parallelise.\n",
    "- **Use `LiveProcessor`** for streaming tokenâ€‘level output.\n",
    "- **Profile:** `asyncio.run(main(), debug=True)` activates slowâ€‘task logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b59c276",
   "metadata": {},
   "source": [
    "## 8. Deployment Snippet<a id='Deployment-Snippet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'DOCKER' > Dockerfile\n",
    "FROM python:3.12-slim\n",
    "WORKDIR /app\n",
    "COPY . /app\n",
    "RUN pip install --no-cache-dir genai-processors uvicorn\n",
    "CMD [\"python\", \"-m\", \"uvicorn\", \"app:router\", \"--host=0.0.0.0\", \"--port=8080\"]\n",
    "DOCKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7c1c8",
   "metadata": {},
   "source": [
    "## 9. Next Steps & Exercises<a id='Next-Steps-&-Exercises'></a>\n",
    "1. **Write a LowercaseTextProcessor** mirroring the uppercase example.\n",
    "2. **Parallel audio transcription + sentiment analysis:** Use `//` to fanâ€‘out.\n",
    "3. **Error handling challenge:** Make a processor that retries Gemini calls with exponential backoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93267a",
   "metadata": {},
   "source": [
    "## 10. Resources<a id='Resources'></a>\n",
    "\n",
    "| Resource | Link |\n",
    "|----------|------|\n",
    "| Blog Announcement | https://developers.googleblog.com/en/genai-processors/ |\n",
    "| GitHub Repo | https://github.com/google-gemini/genai-processors |\n",
    "| Live API Docs | https://ai.google.dev/gemini-api/docs/live |\n",
    "| AsyncIO Primer | https://medium.com/%40Shrishml/all-about-python-asyncio-ca1f5a8974b0 |\n",
    "| uvloop & async performance | https://ai.plainenglish.io/the-role-of-uvloop-in-async-python-for-ai-and-machine-learning-pipelines-c7fec45a4966 |\n",
    "| OpenTools AI overview | https://opentools.ai/news/google-deepmind-launches-genai-processors-revolutionizing-ai-development |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
