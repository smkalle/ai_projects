{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b73ac7",
   "metadata": {},
   "source": [
    "# PyTorch in 1â€¯Hour â€“ Handsâ€‘on Tutorial\n",
    "*Generated on 2025-07-06*\n",
    "\n",
    "This notebook is a distilled, handsâ€‘on companion to **Sebastian Raschkaâ€™s** article *PyTorch in One Hour: From Tensors to Multiâ€‘GPU Training*. Follow the numbered sections to explore core PyTorch concepts and run biteâ€‘sized code examples yourself.\n",
    "\n",
    "ðŸ“š **Reference**: https://sebastianraschka.com/teaching/pytorch-1h/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Compute device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931ea84",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch?\n",
    "At its heart, **PyTorch** provides:\n",
    "1. **Tensors** â€“ Nâ€‘dimensional arrays with GPU acceleration.\n",
    "2. **Autograd** â€“ automatic differentiation for building and training neural networks.\n",
    "3. **`torch.nn` highâ€‘level API** â€“ a library of preâ€‘built layers, loss functions, and utilities.\n",
    "\n",
    "The dynamic computation graph makes debugging intuitive because operations run **eagerly** like regular Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy example: a+b with autograd\n",
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "c = a * b + b\n",
    "c.backward()\n",
    "print('dc/da =', a.grad)\n",
    "print('dc/db =', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1324c7b",
   "metadata": {},
   "source": [
    "## 2. Working with Tensors\n",
    "### 2.1 Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ef972",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((2, 3))\n",
    "y = torch.ones((2, 3))\n",
    "z = torch.rand((2, 3))\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866fb6fe",
   "metadata": {},
   "source": [
    "### 2.2 Tensor attributes & basic ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd263139",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(12).reshape(3, 4)\n",
    "print('Shape:', t.shape)\n",
    "print('Datatype:', t.dtype)\n",
    "print('Device:', t.device)\n",
    "\n",
    "# Broadcasting addition\n",
    "print(t + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a849c9",
   "metadata": {},
   "source": [
    "## 3. Automatic Differentiation (Autograd)\n",
    "`requires_grad` tells PyTorch to track operations on a tensor. After the forward pass, call `.backward()` to populate `.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "output = (w ** 2).sum()\n",
    "output.backward()\n",
    "print('Gradient:', w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396f449",
   "metadata": {},
   "source": [
    "## 4. Building Neural Networks with `nn.Module`\n",
    "A minimal twoâ€‘layer MLP example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc233d4",
   "metadata": {},
   "source": [
    "## 5. Training Loop Essentials\n",
    "Pseudoâ€‘training loop skeleton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af784751",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# dummy oneâ€‘batch train step\n",
    "images = torch.rand((32, 784), device=device)\n",
    "labels = torch.randint(0, 10, (32,), device=device)\n",
    "\n",
    "logits = model(images)\n",
    "loss = loss_fn(logits, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "print('Loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0128e",
   "metadata": {},
   "source": [
    "## 6. Device Management & Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9182792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler()\n",
    "with autocast():\n",
    "    logits = model(images)\n",
    "    loss = loss_fn(logits, labels)\n",
    "scaler.scale(loss).backward()\n",
    "scaler.step(optimizer)\n",
    "scaler.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1b32a",
   "metadata": {},
   "source": [
    "## 7. Multiâ€‘GPU Training Basics\n",
    "Use `torch.nn.DataParallel` for quick mirroring on multiple GPUs or `torch.nn.parallel.DistributedDataParallel` for largeâ€‘scale jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick DataParallel wrapper (works if >1 GPUs detected)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('GPUs:', torch.cuda.device_count())\n",
    "    model = nn.DataParallel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1194318",
   "metadata": {},
   "source": [
    "## 8. Saving & Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c263b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')\n",
    "# Later:\n",
    "loaded_model = Net().to(device)\n",
    "loaded_model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e3593",
   "metadata": {},
   "source": [
    "## 9. Endâ€‘toâ€‘End Miniâ€‘Project\n",
    "Try training the above MLP on **Fashionâ€‘MNIST** or **MNIST**. Use torchvision datasets & transforms. Code omitted for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0aa46",
   "metadata": {},
   "source": [
    "## 10. Next Steps & Resources\n",
    "- Official PyTorch docs <https://pytorch.org/docs>\n",
    "- PyTorch Forums <https://discuss.pytorch.org>\n",
    "- Sebastian Raschkaâ€™s book *Machine Learning with PyTorch and Scikitâ€‘Learn*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
