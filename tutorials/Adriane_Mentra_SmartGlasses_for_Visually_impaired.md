# ğŸ¦¯ Ariadne for Smart Glasses

**AI Assistant for the Visually Impaired â€“ Built with AugmentOS**

> Hands-free scene understanding, sign reading, and object awareness using wearable smart glasses and AI.

---

## ğŸ“– Table of Contents

- [Overview](#-overview)  
- [Features](#-features)  
- [Demo](#-demo)  
- [Setup](#-setup)  
- [Project Structure](#-project-structure)  
- [Step-by-Step Tutorial](#-step-by-step-tutorial)  
  - [1ï¸âƒ£ Scene Description](#1ï¸âƒ£-scene-description)  
  - [2ï¸âƒ£ Sign Reader](#2ï¸âƒ£-sign-reader)  
  - [3ï¸âƒ£ Object Awareness](#3ï¸âƒ£-object-awareness)  
  - [4ï¸âƒ£ Voice Commands](#4ï¸âƒ£-voice-commands)  
- [Enhancements](#-enhancements)  
- [Resources](#-resources)  
- [Contributing](#-contributing)  
- [Acknowledgments](#-acknowledgments)

---

## ğŸš€ Overview

**Ariadne** is an AI-powered assistant for visually impaired users, running on Mentra Live smart glasses with the AugmentOS SDK. It offers real-time:

- Environmental **scene description**  
- **Sign reading** via OCR  
- **Object detection** with spatial awareness  
- **Voice-command-based control**

> This project was created during the [Mentra Ã— Y Combinator Smart Glasses Hackathon â€“ July 2025](https://augmentos.org).

---

## âœ¨ Features

- ğŸ“¸ Take a photo and **describe the scene** with AI-generated captions  
- ğŸ”  Capture text from signs and **read it aloud**  
- ğŸ§­ Identify and position objects in the userâ€™s surroundings  
- ğŸ™ï¸ Respond to spoken commands like "Read sign" or "Describe scene"

---

## ğŸ“¹ Demo

_(Insert your demo video or image preview here, e.g., GIF or YouTube link)_

---

## ğŸ”§ Setup

### Prerequisites

- AugmentOS-compatible smart glasses (e.g., Mentra Live)  
- AugmentOS account and developer access ([console.augmentos.org](https://console.augmentos.org))  
- Node.js + bun + ngrok  
- `.env` file with API credentials (e.g., OpenAI Vision or Google OCR)

### Installation

```bash
git clone https://github.com/your-username/ariadne-smartglasses.git
cd ariadne-smartglasses
bun install
cp .env.example .env  # Add API keys
ngrok http 3000       # Share server endpoint
```

Register your ngrok URL and set display/mic permissions in the AugmentOS Developer Console.

---

## ğŸ“ Project Structure

```bash
ariadne-smartglasses/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.js          # Voice command handler
â”‚   â”œâ”€â”€ scene.js        # Scene description
â”‚   â”œâ”€â”€ ocr.js          # OCR sign reading
â”‚   â”œâ”€â”€ spatial.js      # Object detection with directional mapping
â”‚   â””â”€â”€ utils.js        # Clockface logic + API helpers
â”œâ”€â”€ .env.example        # API config
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## ğŸ§  Step-by-Step Tutorial

### 1ï¸âƒ£ Scene Description

```js
const image = await session.camera.capture();
const caption = await OpenAICaptionAPI(image);
await session.audio.speak(`Scene: ${caption}`);
```

---

### 2ï¸âƒ£ Sign Reader

```js
const image = await session.camera.capture();
const text = await performOCR(image);
await session.audio.speak(`The sign says: ${text}`);
```

---

### 3ï¸âƒ£ Object Awareness

```js
const objects = await detectObjects(image);
const directions = objects.map(obj => `There is a ${obj.label} at ${toClockDirection(obj.x)}`);
await session.audio.speak(directions.join(" "));
```

---

### 4ï¸âƒ£ Voice Commands

```js
session.on('transcription', async (evt) => {
  const t = evt.transcript.toLowerCase();
  if (t.includes('describe')) await describeScene(session);
  if (t.includes('read')) await readSign(session);
  if (t.includes('around')) await describeObjects(session);
});
```

---

## ğŸ” Enhancements

- [ ] Add vibration cue support  
- [ ] Chained commands (e.g., â€œDescribe then readâ€)  
- [ ] Offline ML fallback with ONNX models

---

## ğŸŒ Resources

- [AugmentOS SDK](https://docs.augmentos.org)  
- [OpenAI GPT-Vision](https://platform.openai.com/docs/guides/vision)  
- [Google Vision API](https://cloud.google.com/vision)  
- [BLIP Captioning Model](https://github.com/salesforce/BLIP)  
- [YOLO for Object Detection](https://github.com/ultralytics/yolov5)

---

## ğŸ¤ Contributing

Pull requests welcome! Suggestions for accessibility and features are encouraged.

```bash
git checkout -b feature/my-feature
# Make changes
open a PR ğŸš€
```

---

## ğŸ™ Acknowledgments

- Inspired by the global visually impaired community  
- Thanks to the open-source AI and accessibility ecosystem

> â€œThe world needs to be built for everyone. We just made it a little more audible.â€
