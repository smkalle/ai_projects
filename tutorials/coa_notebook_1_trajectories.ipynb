{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Agents Part 1: Multi-Agent Trajectories from Scratch\n",
    "\n",
    "**Time**: 30 minutes | **Level**: Beginner | **Author**: Karpathy-style CoA Tutorial\n",
    "\n",
    "## The Problem\n",
    "\n",
    "You have a complex task. Traditional approach: Call multiple AI agents, each specialized:\n",
    "- Agent 1 plans ‚Üí costs $0.01, takes 2 seconds\n",
    "- Agent 2 codes ‚Üí costs $0.01, takes 2 seconds  \n",
    "- Agent 3 reviews ‚Üí costs $0.01, takes 2 seconds\n",
    "\n",
    "**Total: $0.03, 6 seconds per request**\n",
    "\n",
    "What if ONE model could do all three in a single call? **$0.01, 2 seconds total.**\n",
    "\n",
    "That's Chain-of-Agents. Let's build it from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: The Simplest Possible Agent\n",
    "\n",
    "No classes. No frameworks. Just a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An agent is just a dictionary with a role\n",
    "def create_agent(name, role):\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"role\": role,\n",
    "        \"history\": []  # We'll record what it does\n",
    "    }\n",
    "\n",
    "# Create our team\n",
    "planner = create_agent(\"Planner\", \"Break down problems into steps\")\n",
    "coder = create_agent(\"Coder\", \"Write code to solve problems\")\n",
    "critic = create_agent(\"Critic\", \"Review and improve solutions\")\n",
    "\n",
    "print(f\"Agent team created: {planner['name']}, {coder['name']}, {critic['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Make Agents \"Think\" (Without LLMs)\n",
    "\n",
    "We'll simulate agent responses. In production, these would be LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_think(agent, task, previous_output=None):\n",
    "    \"\"\"Simulate an agent processing a task\"\"\"\n",
    "    \n",
    "    # Build the prompt (what the agent \"sees\")\n",
    "    prompt = f\"Role: {agent['role']}\\nTask: {task}\"\n",
    "    if previous_output:\n",
    "        prompt += f\"\\nPrevious agent output: {previous_output}\"\n",
    "    \n",
    "    # Simulate different agent behaviors (in reality, this would be an LLM call)\n",
    "    if agent['name'] == \"Planner\":\n",
    "        output = f\"1. Understand {task}\\n2. Design solution\\n3. Implement\\n4. Test\"\n",
    "    elif agent['name'] == \"Coder\":\n",
    "        output = f\"def solve():\\n    # Implementation for: {task[:30]}...\\n    return result\"\n",
    "    else:  # Critic\n",
    "        output = f\"Review: Code looks good. Consider edge cases for {task[:20]}...\"\n",
    "    \n",
    "    # Record what happened\n",
    "    agent['history'].append({\n",
    "        \"input\": prompt,\n",
    "        \"output\": output\n",
    "    })\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test single agent\n",
    "result = agent_think(planner, \"Build a todo app\")\n",
    "print(\"Planner output:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Chain Agents Together\n",
    "\n",
    "This is where the magic happens. Agents pass information to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_chain(agents, task):\n",
    "    \"\"\"Run a chain of agents, each building on the previous output\"\"\"\n",
    "    \n",
    "    trajectory = []  # This records the entire chain - KEY FOR COA!\n",
    "    current_output = None\n",
    "    \n",
    "    print(f\"üéØ Task: {task}\\n\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for agent in agents:\n",
    "        # Agent processes the task\n",
    "        output = agent_think(agent, task, current_output)\n",
    "        \n",
    "        # Record this step in the trajectory\n",
    "        trajectory.append({\n",
    "            \"agent\": agent['name'],\n",
    "            \"role\": agent['role'],\n",
    "            \"input\": current_output if current_output else task,\n",
    "            \"output\": output\n",
    "        })\n",
    "        \n",
    "        # Print what happened\n",
    "        print(f\"\\n[{agent['name']}]\")\n",
    "        print(output[:100] + \"...\" if len(output) > 100 else output)\n",
    "        \n",
    "        # Pass output to next agent\n",
    "        current_output = output\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    return trajectory\n",
    "\n",
    "# Run the chain!\n",
    "trajectory = run_agent_chain([planner, coder, critic], \"Build a todo app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the Trajectory\n",
    "\n",
    "Let's see what we just recorded. This trajectory is what we'll use to train our AFM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trajectory(trajectory):\n",
    "    \"\"\"ASCII art visualization of agent chain\"\"\"\n",
    "    \n",
    "    print(\"\\nüîó CHAIN-OF-AGENTS TRAJECTORY:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, step in enumerate(trajectory):\n",
    "        # Box for each agent\n",
    "        print(f\"\\n‚îå‚îÄ Step {i+1}: {step['agent']} {'‚îÄ'*(40-len(step['agent']))}‚îê\")\n",
    "        print(f\"‚îÇ Role: {step['role'][:45]:<45} ‚îÇ\")\n",
    "        print(f\"‚îÇ Output: {step['output'][:42]:<42}... ‚îÇ\")\n",
    "        print(f\"‚îî{'‚îÄ'*50}‚îò\")\n",
    "        \n",
    "        # Arrow to next step\n",
    "        if i < len(trajectory) - 1:\n",
    "            print(\" \"*25 + \"‚Üì\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Total steps: {len(trajectory)}\")\n",
    "    print(f\"Agents involved: {', '.join(set(s['agent'] for s in trajectory))}\")\n",
    "\n",
    "visualize_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: The Key Insight - Multiple Trajectories\n",
    "\n",
    "To train an AFM, we need MANY trajectories. Let's generate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different tasks to solve\n",
    "tasks = [\n",
    "    \"Build a todo app\",\n",
    "    \"Create a REST API\",\n",
    "    \"Design a database schema\",\n",
    "    \"Implement user authentication\",\n",
    "    \"Optimize a slow query\"\n",
    "]\n",
    "\n",
    "# Generate trajectories for all tasks\n",
    "all_trajectories = []\n",
    "\n",
    "for task in tasks:\n",
    "    print(f\"\\nüìù Generating trajectory for: {task}\")\n",
    "    trajectory = run_agent_chain([planner, coder, critic], task)\n",
    "    all_trajectories.append({\n",
    "        \"task\": task,\n",
    "        \"trajectory\": trajectory,\n",
    "        \"num_steps\": len(trajectory)\n",
    "    })\n",
    "    print(f\"   ‚úì Generated {len(trajectory)} steps\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total trajectories collected: {len(all_trajectories)}\")\n",
    "print(f\"üìä Total agent steps recorded: {sum(t['num_steps'] for t in all_trajectories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Trajectory Statistics\n",
    "\n",
    "Let's understand what we've collected. This helps us see patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trajectories(trajectories):\n",
    "    \"\"\"Analyze trajectory patterns - useful for understanding CoA\"\"\"\n",
    "    \n",
    "    # Count agent appearances\n",
    "    agent_counts = {}\n",
    "    total_steps = 0\n",
    "    \n",
    "    for traj_data in trajectories:\n",
    "        for step in traj_data['trajectory']:\n",
    "            agent = step['agent']\n",
    "            agent_counts[agent] = agent_counts.get(agent, 0) + 1\n",
    "            total_steps += 1\n",
    "    \n",
    "    # Print analysis\n",
    "    print(\"üìä TRAJECTORY ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total trajectories: {len(trajectories)}\")\n",
    "    print(f\"Total steps: {total_steps}\")\n",
    "    print(f\"Avg steps per task: {total_steps/len(trajectories):.1f}\")\n",
    "    print(\"\\nAgent participation:\")\n",
    "    for agent, count in agent_counts.items():\n",
    "        percentage = (count/total_steps)*100\n",
    "        bar = '‚ñà' * int(percentage/5)\n",
    "        print(f\"  {agent:10} {bar:20} {percentage:.1f}%\")\n",
    "    \n",
    "    return agent_counts\n",
    "\n",
    "stats = analyze_trajectories(all_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Simulate Traditional vs CoA Performance\n",
    "\n",
    "Let's see why CoA is revolutionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def simulate_traditional_multi_agent(task, agents):\n",
    "    \"\"\"Simulate traditional approach: multiple LLM calls\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    costs = []\n",
    "    for agent in agents:\n",
    "        # Simulate API call\n",
    "        time.sleep(0.5)  # Simulate network latency\n",
    "        costs.append(0.01)  # $0.01 per call\n",
    "    \n",
    "    total_time = time.time() - start\n",
    "    total_cost = sum(costs)\n",
    "    \n",
    "    return {\n",
    "        \"approach\": \"Traditional Multi-Agent\",\n",
    "        \"time\": total_time,\n",
    "        \"cost\": total_cost,\n",
    "        \"api_calls\": len(agents)\n",
    "    }\n",
    "\n",
    "def simulate_coa_afm(task):\n",
    "    \"\"\"Simulate CoA approach: single AFM call\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Single API call to AFM\n",
    "    time.sleep(0.5)  # Simulate network latency\n",
    "    cost = 0.01  # Single call cost\n",
    "    \n",
    "    total_time = time.time() - start\n",
    "    \n",
    "    return {\n",
    "        \"approach\": \"CoA (AFM)\",\n",
    "        \"time\": total_time,\n",
    "        \"cost\": cost,\n",
    "        \"api_calls\": 1\n",
    "    }\n",
    "\n",
    "# Compare approaches\n",
    "print(\"‚ö° PERFORMANCE COMPARISON\\n\" + \"=\"*40)\n",
    "\n",
    "traditional = simulate_traditional_multi_agent(\"Build app\", [planner, coder, critic])\n",
    "coa = simulate_coa_afm(\"Build app\")\n",
    "\n",
    "for approach in [traditional, coa]:\n",
    "    print(f\"\\n{approach['approach']}:\")\n",
    "    print(f\"  Time: {approach['time']:.2f}s\")\n",
    "    print(f\"  Cost: ${approach['cost']:.2f}\")\n",
    "    print(f\"  API calls: {approach['api_calls']}\")\n",
    "\n",
    "# Show improvement\n",
    "speedup = traditional['time'] / coa['time']\n",
    "cost_reduction = (1 - coa['cost']/traditional['cost']) * 100\n",
    "\n",
    "print(f\"\\nüöÄ CoA IMPROVEMENTS:\")\n",
    "print(f\"  {speedup:.1f}x faster\")\n",
    "print(f\"  {cost_reduction:.0f}% cheaper\")\n",
    "print(f\"  {traditional['api_calls'] - coa['api_calls']} fewer API calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Prepare Trajectories for Training\n",
    "\n",
    "Transform our trajectories into training data for the AFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_to_training_data(trajectory_data):\n",
    "    \"\"\"Convert trajectory to format suitable for training\"\"\"\n",
    "    \n",
    "    # Build the full conversation\n",
    "    conversation = f\"Task: {trajectory_data['task']}\\n\\n\"\n",
    "    \n",
    "    for step in trajectory_data['trajectory']:\n",
    "        # Add agent marker (this teaches the model to simulate different agents)\n",
    "        conversation += f\"[{step['agent']}]: {step['output']}\\n\\n\"\n",
    "    \n",
    "    # Create training example\n",
    "    return {\n",
    "        \"input\": trajectory_data['task'],\n",
    "        \"output\": conversation,\n",
    "        \"metadata\": {\n",
    "            \"num_agents\": len(set(s['agent'] for s in trajectory_data['trajectory'])),\n",
    "            \"num_steps\": len(trajectory_data['trajectory'])\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Convert all trajectories\n",
    "training_data = [trajectory_to_training_data(t) for t in all_trajectories]\n",
    "\n",
    "# Show example\n",
    "print(\"üìö TRAINING DATA EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "example = training_data[0]\n",
    "print(f\"Input: {example['input']}\")\n",
    "print(f\"\\nOutput (what AFM will learn to generate):\")\n",
    "print(\"-\"*40)\n",
    "print(example['output'][:300] + \"...\")\n",
    "print(\"-\"*40)\n",
    "print(f\"\\nMetadata: {example['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Beat My Implementation üèÜ\n",
    "\n",
    "Can you create a better agent chain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your own agent chain that performs better\n",
    "# Hints:\n",
    "# 1. Add more specialized agents\n",
    "# 2. Change the order of agents\n",
    "# 3. Make agents more specific to certain tasks\n",
    "\n",
    "def your_agent_chain():\n",
    "    \"\"\"Create your improved agent chain\"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    # Example: Add a \"Debugger\" agent, or \"Optimizer\" agent\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Baseline to beat: 3 agents, 3 steps\n",
    "print(\"Baseline: 3 agents, sequential execution\")\n",
    "print(\"Can you design a more efficient chain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Trajectory Quality Score üìä\n",
    "\n",
    "Not all trajectories are good for training. Implement a quality scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_trajectory(trajectory):\n",
    "    \"\"\"Score trajectory quality (0-100)\"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    # TODO: Implement scoring logic\n",
    "    # Ideas:\n",
    "    # - Longer outputs might be better (+points)\n",
    "    # - All agents participating is good (+points)  \n",
    "    # - Repetitive outputs are bad (-points)\n",
    "    # - Clear task completion is good (+points)\n",
    "    \n",
    "    # Your implementation here\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Test your scorer\n",
    "for traj in all_trajectories[:3]:\n",
    "    score = score_trajectory(traj['trajectory'])\n",
    "    print(f\"Task: {traj['task'][:30]}... Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Minimal CoA Implementation üéØ\n",
    "\n",
    "Implement the core CoA concept in under 50 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Implement core CoA in < 50 lines\n",
    "# Must include:\n",
    "# 1. Agent creation\n",
    "# 2. Trajectory recording\n",
    "# 3. Training data generation\n",
    "\n",
    "def minimal_coa(task):\n",
    "    \"\"\"Your minimal Chain-of-Agents implementation\"\"\"\n",
    "    \n",
    "    # Your code here (keep it under 50 lines!)\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Line count check\n",
    "import inspect\n",
    "lines = len(inspect.getsource(minimal_coa).split('\\n'))\n",
    "print(f\"Your implementation: {lines} lines\")\n",
    "print(f\"Target: < 50 lines\")\n",
    "print(f\"Status: {'‚úÖ PASS' if lines < 50 else '‚ùå TOO LONG'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways üéì\n",
    "\n",
    "1. **Trajectories are key**: Recording agent interactions is what makes CoA possible\n",
    "2. **Simple data structure**: Trajectories are just lists of (agent, input, output)\n",
    "3. **Massive efficiency gains**: 3x faster, 66% cheaper than traditional multi-agent\n",
    "4. **Training data**: Each trajectory becomes an example for the AFM to learn\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In Part 2, we'll implement **Progressive Filtering** to select only high-quality trajectories for training. This is crucial for getting that 55.3% GAIA performance!\n",
    "\n",
    "## Your Homework üìù\n",
    "\n",
    "1. Generate 100 trajectories with different tasks\n",
    "2. Implement a trajectory visualizer using matplotlib (not just ASCII)\n",
    "3. Try different agent configurations and measure the difference\n",
    "4. Read the CoA paper section on trajectory generation\n",
    "\n",
    "Remember: **We just replaced 3 LLM calls with training data for 1 model!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}