# ==============================================================================
# VECTOR MATCHUP PRO - ENVIRONMENT CONFIGURATION
# ==============================================================================
# Copy this file to .env and customize according to your needs

# ==============================================================================
# EMBEDDING MODEL CONFIGURATION
# ==============================================================================

# Currently active embedding model
# Choose from the options below based on your use case
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ==============================================================================
# AVAILABLE EMBEDDING MODELS BY CATEGORY
# ==============================================================================

# ===== ENGLISH-FOCUSED MODELS (Fast & Efficient) =====
# Small models with good English performance
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2        # 384 dims, 80MB, Fast, English
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L12-v2       # 384 dims, 120MB, Better quality
# EMBEDDING_MODEL=sentence-transformers/paraphrase-MiniLM-L6-v2 # 384 dims, 80MB, Paraphrase detection

# Medium models with better English performance
# EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2       # 768 dims, 420MB, High quality English
# EMBEDDING_MODEL=sentence-transformers/all-distilroberta-v1    # 768 dims, 290MB, RoBERTa-based

# ===== MULTILINGUAL MODELS (Global Support) =====
# Best overall multilingual performance (Recommended for production)
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2  # 384 dims, 420MB, 50+ languages
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2  # 768 dims, 970MB, Best quality
# EMBEDDING_MODEL=sentence-transformers/distiluse-base-multilingual-cased      # 512 dims, 480MB, Good balance

# Latest E5 multilingual models (2024 state-of-the-art)
# EMBEDDING_MODEL=intfloat/multilingual-e5-small               # 384 dims, 470MB, Very good performance
# EMBEDDING_MODEL=intfloat/multilingual-e5-base                # 768 dims, 1.1GB, Better performance
# EMBEDDING_MODEL=intfloat/multilingual-e5-large               # 1024 dims, 2.2GB, Best performance
# EMBEDDING_MODEL=intfloat/multilingual-e5-large-instruct      # 1024 dims, 2.2GB, Instruction-tuned

# Latest BGE multilingual models (2024 Chinese focus)
# EMBEDDING_MODEL=BAAI/bge-m3                                   # 1024 dims, 2.2GB, 100+ languages, Dense+Sparse
# EMBEDDING_MODEL=BAAI/bge-multilingual-gemma2                 # 768 dims, 1.5GB, Gemma2-based

# ===== SPECIALIZED MODELS =====
# For specific domains or requirements

# Code and technical content
# EMBEDDING_MODEL=microsoft/codebert-base                      # 768 dims, 490MB, Code understanding

# Legal and scientific documents  
# EMBEDDING_MODEL=sentence-transformers/allenai-specter        # 768 dims, 440MB, Scientific papers

# ===== ULTRA-FAST STATIC MODELS (2024 Innovation) =====
# Static embedding models - 100x faster CPU inference
# EMBEDDING_MODEL=sentence-transformers/static-retrieval-mrl-en-v1           # 1024 dims, English retrieval
# EMBEDDING_MODEL=sentence-transformers/static-similarity-mrl-multilingual-v1 # 1024 dims, Multilingual similarity

# ==============================================================================
# PERFORMANCE CHARACTERISTICS REFERENCE
# ==============================================================================
#
# | Model Type          | Languages | Speed    | Quality | Use Case                    |
# |---------------------|-----------|----------|---------|----------------------------|
# | all-MiniLM-L6-v2    | English   | Very Fast| Good   | Development/Testing        |
# | all-mpnet-base-v2   | English   | Fast     | High   | English production         |
# | multilingual-e5-*   | 100+      | Medium   | Best   | Global production          |
# | bge-m3              | 100+      | Medium   | Best   | China/Asia focus           |
# | static-*            | Various   | Ultra    | Good   | Edge/Mobile deployment     |
#
# RECOMMENDATIONS:
# - Development/Testing: all-MiniLM-L6-v2 (fast, good enough)
# - English Production: all-mpnet-base-v2 (best English quality)
# - Multilingual Production: multilingual-e5-large (best overall)
# - Resource Constrained: multilingual-e5-small (good balance)
# - Edge/Mobile: static-similarity-mrl-multilingual-v1 (ultra-fast)

# ==============================================================================
# OTHER CONFIGURATION OPTIONS
# ==============================================================================

# System Configuration
# EMBEDDING_DEVICE=cpu                    # Options: cpu, cuda, mps (Apple Silicon)
# EMBEDDING_BATCH_SIZE=32                 # Batch size for encoding
# EMBEDDING_MAX_LENGTH=512                # Maximum sequence length
# EMBEDDING_NORMALIZE=true                # Normalize embeddings for cosine similarity

# Performance Tuning
# EMBEDDING_CACHE_SIZE=1000               # Number of embeddings to cache
# EMBEDDING_PARALLEL_WORKERS=4            # Number of parallel workers

# OpenAI Configuration (if using OpenAI embeddings)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small  # or text-embedding-3-large

# Model Download Configuration
# HF_TOKEN=your-huggingface-token         # For private models
# MODEL_CACHE_DIR=./models                # Local model cache directory 